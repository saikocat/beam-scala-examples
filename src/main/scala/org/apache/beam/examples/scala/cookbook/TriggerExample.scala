/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package org.apache.beam.examples.scala.cookbook

import java.util.concurrent.TimeUnit

import scala.collection.JavaConverters._
import scala.util.Random

import com.google.api.services.bigquery.model.{
  TableFieldSchema,
  TableReference,
  TableRow,
  TableSchema
}
import org.apache.beam.examples.common.{ExampleBigQueryTableOptions, ExampleOptions, ExampleUtils}
import org.apache.beam.examples.scala.typealias._
import org.apache.beam.sdk.{Pipeline, PipelineResult}
import org.apache.beam.sdk.io.TextIO
import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO
import org.apache.beam.sdk.options._
import org.apache.beam.sdk.transforms.{DoFn, GroupByKey, PTransform, ParDo}
import org.apache.beam.sdk.transforms.DoFn.ProcessElement
import org.apache.beam.sdk.transforms.windowing.{
  AfterEach,
  AfterProcessingTime,
  AfterWatermark,
  BoundedWindow,
  FixedWindows,
  Repeatedly,
  Window
}
import org.apache.beam.sdk.values.{KV, PCollection, PCollectionList}
import org.joda.time.{Duration, Instant}

object TriggerExample {
  // Numeric value of fixed window duration, in minutes
  final val WINDOW_DURATION = 30
  // Constants used in triggers.
  // Speeding up ONE_MINUTE or FIVE_MINUTES helps you get an early approximation of results.
  // ONE_MINUTE is used only with processing time before the end of the window
  final val ONE_MINUTE: Duration = Duration.standardMinutes(1)
  // FIVE_MINUTES is used only with processing time after the end of the window
  final val FIVE_MINUTES: Duration = Duration.standardMinutes(5)
  // ONE_DAY is used to specify the amount of lateness allowed for the data elements.
  final val ONE_DAY: Duration = Duration.standardDays(1)

  def main(args: Array[String]): Unit = {
    val options = PipelineOptionsFactory
      .fromArgs(args: _*)
      .withValidation()
      .as(classOf[TrafficFlowOptions])
    options.setStreaming(true)
    options.setBigQuerySchema(getSchema())

    val exampleUtils = new ExampleUtils(options)
    exampleUtils.setup()

    val pipeline = Pipeline.create(options)
    val tableRef: TableReference =
      getTableReference(options.getProject, options.getBigQueryDataset, options.getBigQueryTable)

    val resultList: PCollectionList[TableRow] =
      pipeline
        .apply("ReadMyFile", TextIO.read().from(options.getInput))
        .apply("InsertRandomDelays", ParDo.of(new InsertDelaysFn()))
        .apply(ParDo.of(new ExtractFlowInfoFn()))
        .apply(new CalculateTotalFlow(options.getWindowDuration))

    for (idx <- 0 until resultList.size()) {
      resultList
        .get(idx)
        .apply(
          BigQueryIO
            .writeTableRows()
            .to(tableRef)
            .withSchema(getSchema()))
    }

    val result: PipelineResult = pipeline.run()

    // ExampleUtils will try to cancel the pipeline and the injector before the program exits.
    exampleUtils.waitToFinish(result)
  }

  trait TrafficFlowOptions
      extends ExampleOptions
      with ExampleBigQueryTableOptions
      with StreamingOptions {
    @Description("Input file to read from")
    @Default.String(
      "gs://apache-beam-samples/traffic_sensor/Freeways-5Minaa2010-01-01_to_2010-02-15.csv")
    def getInput(): String
    def setInput(value: String): Unit

    @Description("Numeric value of window duration for fixed windows, in minutes")
    @Default.Integer(WINDOW_DURATION)
    def getWindowDuration: JInteger
    def setWindowDuration(value: JInteger): Unit
  }

  /**
    * This transform demonstrates using triggers to control when data is produced for each window
    * Consider an example to understand the results generated by each type of trigger. The example
    * uses "freeway" as the key. Event time is the timestamp associated with the data element and
    * processing time is the time when the data element gets processed in the pipeline. For freeway
    * 5, suppose there are 10 elements in the [10:00:00, 10:30:00) window. Key (freeway) | Value
    * (total_flow) | event time | processing time 5 | 50 | 10:00:03 | 10:00:47 5 | 30 | 10:01:00 |
    * 10:01:03 5 | 30 | 10:02:00 | 11:07:00 5 | 20 | 10:04:10 | 10:05:15 5 | 60 | 10:05:00 | 11:03:00
    * 5 | 20 | 10:05:01 | 11.07:30 5 | 60 | 10:15:00 | 10:27:15 5 | 40 | 10:26:40 | 10:26:43 5 | 60 |
    * 10:27:20 | 10:27:25 5 | 60 | 10:29:00 | 11:11:00
    *
    * Beam tracks a watermark which records up to what point in event time the data is complete.
    * For the purposes of the example, we'll assume the watermark is approximately 15m behind the
    * current processing time. In practice, the actual value would vary over time based on the
    * systems knowledge of the current delay and contents of the backlog (data that has not yet been
    * processed).
    *
    * If the watermark is 15m behind, then the window [10:00:00, 10:30:00) (in event time) would
    * close at 10:44:59, when the watermark passes 10:30:00.
    */
  class CalculateTotalFlow(windowDuration: Int)
      extends PTransform[PCollection[KV[String, JInteger]], PCollectionList[TableRow]] {

    override def expand(flowInfo: PCollection[KV[String, JInteger]]): PCollectionList[TableRow] = {

      // Concept #1: The default triggering behavior
      // By default Beam uses a trigger which fires when the watermark has passed the end of the
      // window. This would be written Repeatedly.forever(AfterWatermark.pastEndOfWindow()).

      // The system also defaults to dropping late data -- data which arrives after the watermark
      // has passed the event timestamp of the arriving element. This means that the default trigger
      // will only fire once.

      // Each pane produced by the default trigger with no allowed lateness will be the first and
      // last pane in the window, and will be ON_TIME.

      // The results for the example above with the default trigger and zero allowed lateness
      // would be:
      // Key (freeway) | Value (total_flow) | number_of_records | isFirst | isLast | timing
      // 5             | 260                | 6                 | true    | true   | ON_TIME

      // At 11:03:00 (processing time) the system watermark may have advanced to 10:54:00. As a
      // result, when the data record with event time 10:05:00 arrives at 11:03:00, it is considered
      // late, and dropped.
      val defaultTriggerResults: PCollection[TableRow] =
        flowInfo
          .apply(
            "Default",
            Window
            // The default window duration values work well if you're running the default
              // input file. You may want to adjust the window duration otherwise.
              .into[KV[String, JInteger]](
                FixedWindows.of(Duration.standardMinutes(windowDuration.toLong)))
              // The default trigger first emits output when the system's watermark passes
                // the end of the window.
              .triggering(Repeatedly.forever(AfterWatermark.pastEndOfWindow()))
                // Late data is dropped
              .withAllowedLateness(Duration.ZERO)
              // Discard elements after emitting each pane.
              // With no allowed lateness and the specified trigger there will only be a
                // single pane, so this doesn't have a noticeable effect. See concept 2 for more details.
              .discardingFiredPanes()
          )
          .apply(new TotalFlow("default"))

      // Concept #2: Late data with the default trigger
      // This uses the same trigger as concept #1, but allows data that is up to ONE_DAY late. This
      // leads to each window staying open for ONE_DAY after the watermark has passed the end of the
      // window. Any late data will result in an additional pane being fired for that same window.

      // The first pane produced will be ON_TIME and the remaining panes will be LATE.
      // To definitely get the last pane when the window closes, use
      // .withAllowedLateness(ONE_DAY, ClosingBehavior.FIRE_ALWAYS).

      // The results for the example above with the default trigger and ONE_DAY allowed lateness
      // would be:
      // Key (freeway) | Value (total_flow) | number_of_records | isFirst | isLast | timing
      // 5             | 260                | 6                 | true    | false  | ON_TIME
      // 5             | 60                 | 1                 | false   | false  | LATE
      // 5             | 30                 | 1                 | false   | false  | LATE
      // 5             | 20                 | 1                 | false   | false  | LATE
      // 5             | 60                 | 1                 | false   | false  | LATE
      val withAllowedLatenessResults: PCollection[TableRow] =
        flowInfo
          .apply(
            "WithLateData",
            Window
              .into[KV[String, JInteger]](
                FixedWindows.of(Duration.standardMinutes(windowDuration.toLong)))
                // Late data is emitted as it arrives
              .triggering(Repeatedly.forever(AfterWatermark.pastEndOfWindow()))
              // Once the output is produced, the pane is dropped and we start preparing the
                // next pane for the window
              .discardingFiredPanes()
                // Late data is handled up to one day
              .withAllowedLateness(ONE_DAY)
          )
          .apply(new TotalFlow("withAllowedLateness"))

      // Concept #3: How to get speculative estimates
      // We can specify a trigger that fires independent of the watermark, for instance after
      // ONE_MINUTE of processing time. This allows us to produce speculative estimates before
      // all the data is available. Since we don't have any triggers that depend on the watermark
      // we don't get an ON_TIME firing. Instead, all panes are either EARLY or LATE.

      // We also use accumulatingFiredPanes to build up the results across each pane firing.

      // The results for the example above for this trigger would be:
      // Key (freeway) | Value (total_flow) | number_of_records | isFirst | isLast | timing
      // 5             | 80                 | 2                 | true    | false  | EARLY
      // 5             | 100                | 3                 | false   | false  | EARLY
      // 5             | 260                | 6                 | false   | false  | EARLY
      // 5             | 320                | 7                 | false   | false  | LATE
      // 5             | 370                | 9                 | false   | false  | LATE
      // 5             | 430                | 10                | false   | false  | LATE
      val speculativeResults: PCollection[TableRow] =
        flowInfo
          .apply(
            "Speculative",
            Window
              .into[KV[String, JInteger]](
                FixedWindows.of(Duration.standardMinutes(windowDuration.toLong)))
                // Trigger fires every minute.
              .triggering(Repeatedly.forever(AfterProcessingTime.pastFirstElementInPane
                // Speculative every ONE_MINUTE
                .plusDelayOf(ONE_MINUTE)))
              // After emitting each pane, it will continue accumulating the elements so that each
                // approximation includes all of the previous data in addition to the newly arrived data.
              .accumulatingFiredPanes()
              .withAllowedLateness(ONE_DAY)
          )
          .apply(new TotalFlow("speculative"))

      // Concept #4: Combining late data and speculative estimates
      // We can put the previous concepts together to get EARLY estimates, an ON_TIME result,
      // and LATE updates based on late data.

      // Each time a triggering condition is satisfied it advances to the next trigger.
      // If there are new elements this trigger emits a window under following condition:
      // > Early approximations every minute till the end of the window.
      // > An on-time firing when the watermark has passed the end of the window
      // > Every five minutes of late data.

      // Every pane produced will either be EARLY, ON_TIME or LATE.

      // The results for the example above for this trigger would be:
      // Key (freeway) | Value (total_flow) | number_of_records | isFirst | isLast | timing
      // 5             | 80                 | 2                 | true    | false  | EARLY
      // 5             | 100                | 3                 | false   | false  | EARLY
      // 5             | 260                | 6                 | false   | false  | EARLY
      // [First pane fired after the end of the window]
      // 5             | 320                | 7                 | false   | false  | ON_TIME
      // 5             | 430                | 10                | false   | false  | LATE

      // For more possibilities of how to build advanced triggers, see {@link Trigger}.
      val sequentialResults: PCollection[TableRow] =
        flowInfo
          .apply(
            "Sequential",
            Window
              .into[KV[String, JInteger]](
                FixedWindows.of(Duration.standardMinutes(windowDuration.toLong)))
              .triggering(AfterEach.inOrder(
                Repeatedly
                  .forever(AfterProcessingTime
                    .pastFirstElementInPane()
                      // Speculative every ONE_MINUTE
                    .plusDelayOf(ONE_MINUTE))
                  .orFinally(AfterWatermark.pastEndOfWindow()),
                Repeatedly.forever(AfterProcessingTime
                  .pastFirstElementInPane()
                    // Late data every FIVE_MINUTES
                  .plusDelayOf(FIVE_MINUTES))
              ))
              .accumulatingFiredPanes()
                // For up to ONE_DAY
              .withAllowedLateness(ONE_DAY)
          )
          .apply(new TotalFlow("sequential"));

      // Adds the results generated by each trigger type to a PCollectionList.
      val resultsList: PCollectionList[TableRow] =
        PCollectionList
          .of(defaultTriggerResults)
          .and(withAllowedLatenessResults)
          .and(speculativeResults)
          .and(sequentialResults)

      resultsList
    }
  }

  /**
    * Calculate total flow and number of records for each freeway and format the results to TableRow
    * objects, to save to BigQuery.
    */
  class TotalFlow(triggerType: String)
      extends PTransform[PCollection[KV[String, JInteger]], PCollection[TableRow]] {
    override def expand(flowInfo: PCollection[KV[String, JInteger]]): PCollection[TableRow] = {
      val flowPerFreeway: PCollection[KV[String, JIterable[JInteger]]] =
        flowInfo.apply(GroupByKey.create())
      val results: PCollection[KV[String, String]] =
        flowPerFreeway.apply(ParDo.of(new SumCountRecordFn()))
      val output: PCollection[TableRow] =
        results.apply(ParDo.of(new FormatTotalFlowFn(triggerType)))
      output
    }
  }

  // helper fn instead of anon fn to make linter happy
  class SumCountRecordFn extends DoFn[KV[String, JIterable[Integer]], KV[String, String]] {
    @ProcessElement
    def processElement(ctx: ProcessContext): Unit = {
      val flows: JIterable[Integer] = ctx.element.getValue
      val (sum, numberOfRecords) = flows.asScala.foldLeft((0, 0L)) { (acc, value) =>
        (acc._1 + value, acc._2 + 1)
      }
      ctx.output(KV.of(ctx.element.getKey, s"$sum, $numberOfRecords"))
    }
  }

  /**
    * Format the results of the Total flow calculation to a TableRow, to save to BigQuery. Adds the
    * triggerType, pane information, processing time and the window timestamp.
    */
  class FormatTotalFlowFn(triggerType: String) extends DoFn[KV[String, String], TableRow] {
    @ProcessElement
    def processElement(ctx: ProcessContext, window: BoundedWindow): Unit = {
      val values = ctx.element.getValue.split(",", -1)
      // Exception fest if unable to parse int or long
      val row: TableRow =
        new TableRow()
          .set("trigger_type", triggerType)
          .set("freeway", ctx.element.getKey)
          .set("total_flow", Integer.parseInt(values(0)))
          .set("number_of_records", Long2long(values(1).toLong))
          .set("window", window.toString)
          .set("isFirst", ctx.pane.isFirst)
          .set("isLast", ctx.pane.isLast)
          .set("timing", ctx.pane.getTiming.toString)
          .set("event_time", ctx.timestamp.toString)
          .set("processing_time", Instant.now().toString)
      ctx.output(row)
    }
  }

  /**
    * Extract the freeway and total flow in a reading. Freeway is used as key since we are
    * calculating the total flow for each freeway.
    */
  class ExtractFlowInfoFn extends DoFn[String, KV[String, JInteger]] {
    private final val VALID_NUM_FIELDS = 50

    @ProcessElement
    def processElement(ctx: ProcessContext): Unit = {
      val laneInfo = ctx.element.split(",", -1)

      for {
        totalFlow <- scala.util.Try(laneInfo(7).toInt)
        freeway = laneInfo(2)
        // Skip the invalid input.
        if laneInfo.length >= VALID_NUM_FIELDS
        // Header row
        if laneInfo(0) != "timestamp"
        // Ignore the records with total flow 0 to easily understand the working of triggers.
        // Skip the records with total flow -1 since they are invalid input.
        if totalFlow > 0
      } ctx.output(KV.of(freeway, totalFlow))
    }
  }

  /** Add current time to each record. Also insert a delay at random to demo the triggers. */
  class InsertDelaysFn extends DoFn[String, String] {
    private final val THRESHOLD = 0.001
    // MIN_DELAY and MAX_DELAY in minutes.
    private final val MIN_DELAY = 1
    private final val MAX_DELAY = 100

    @ProcessElement
    def processElement(ctx: ProcessContext): Unit = {
      val random = new Random()
      val now: Instant = Instant.now()
      val timestamp: Instant = (random.nextDouble < THRESHOLD) match {
        case false => now
        case true => {
          val range = MAX_DELAY - MIN_DELAY
          val delayInMinutes = random.nextInt(range) + MIN_DELAY
          val delayInMillis = TimeUnit.MINUTES.toMillis(delayInMinutes.toLong)
          new Instant(now.getMillis - delayInMillis)
        }
      }
      ctx.outputWithTimestamp(ctx.element, timestamp)
    }
  }

  /** Sets the table reference. */
  def getTableReference(project: String, dataset: String, table: String): TableReference =
    new TableReference()
      .setProjectId(project)
      .setDatasetId(dataset)
      .setTableId(table)

  /** Defines the BigQuery schema used for the output. */
  def getSchema(): TableSchema = {
    val fields: List[TableFieldSchema] = List(
      new TableFieldSchema().setName("trigger_type").setType("STRING"),
      new TableFieldSchema().setName("freeway").setType("STRING"),
      new TableFieldSchema().setName("total_flow").setType("INTEGER"),
      new TableFieldSchema().setName("number_of_records").setType("INTEGER"),
      new TableFieldSchema().setName("window").setType("STRING"),
      new TableFieldSchema().setName("isFirst").setType("BOOLEAN"),
      new TableFieldSchema().setName("isLast").setType("BOOLEAN"),
      new TableFieldSchema().setName("timing").setType("STRING"),
      new TableFieldSchema().setName("event_time").setType("TIMESTAMP"),
      new TableFieldSchema().setName("processing_time").setType("TIMESTAMP")
    )
    new TableSchema().setFields(fields.asJava)
  }
}
